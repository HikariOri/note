# 线性代数与矩阵分析基础

## 向量空间（Vector Space）

<div class="math-env definition" data-name="向量空间">

数域 $\mathbb{F}$ 上的一个向量空间是一个集合 $V$，$V$ 上的加法和标量乘法满足以下性质：

- 向量加法结合律：$\boldsymbol{u}+\left( \boldsymbol{v}+\boldsymbol{w} \right) =\left( \boldsymbol{u}+\boldsymbol{v} \right) +\boldsymbol{w}$
- 向量加法交换律：$\boldsymbol{u}+\boldsymbol{v}=\boldsymbol{v}+\boldsymbol{u}$
- 向量加法单位元：$\boldsymbol{v}+\boldsymbol{0}=\boldsymbol{v}$
- 向量加法逆元：$\boldsymbol{v}+\left( \boldsymbol{-v} \right) =\boldsymbol{0}$
- 标量乘法与数域乘法的结合律：$a\left( b \boldsymbol{v} \right) =\left( a b \right) \boldsymbol{v}$
- 标量乘法单位元：$1 \boldsymbol{v}=\boldsymbol{v}$
- 标量乘法对向量加法的分配律：$a\left( \boldsymbol{u}+\boldsymbol{v} \right) =a \boldsymbol{u} + a \boldsymbol{v}$
- 标量乘法对数域加法的分配律：$\left( a+b \right) \boldsymbol{v}=a \boldsymbol{v}+b \boldsymbol{v}$

</div>

<div class="math-env remark">

$\mathbb{F}$ 一般取 $\mathbb{R}$ 或 $\mathbb{C}$

</div>


<div class="math-env definition" data-name="线性组合">

$V$ 中的向量组 $\boldsymbol{v}_1,\boldsymbol{v}_2,\cdots,\boldsymbol{v}_m$ 的线性组合是形如

$$
a_1 \boldsymbol{v}_1+a_2 \boldsymbol{v}_2+\cdots+a_m \boldsymbol{v}_m
$$

的向量，其中 $a_1,a_2,\cdots,a_n \in \mathbb{F}$.

</div>

<div class="math-env definition" data-name="线性无关/线性相关（Linearly dependent/independent"）>

对于向量集合 $\left\{ \boldsymbol{u}_1, \boldsymbol{u}_2,\cdots,\boldsymbol{u}_n \right\}$，线性相关指的是，在 $\mathbb{F}$ 中存在不全为 $0$ 的一组数 $a_1,a_2,\cdots,a_n$ 使得：

$$
a_1 \boldsymbol{u}_1+a_2 \boldsymbol{u}_2+\cdots a_n\boldsymbol{u}_n=0
$$

即：

$$
\boldsymbol{u}_1=-\frac{a_2}{a_1}\boldsymbol{u}_2-\frac{a_3}{a_1}\boldsymbol{u}_3-\cdots-\frac{a_n}{a_1}\boldsymbol{u}_n\,\,\,\,(a_1\neq 0)
$$

说明 $\boldsymbol{u}_1$ 是 $\boldsymbol{u}_2,\boldsymbol{u}_3,\cdots,\boldsymbol{u}_n$ 的线性组合.

线性无关：$\mathbb{F}$ 中不存在不全为 $0$ 的这样的一组数.

</div>


### 向量空间的维数

<div class="math-env definition" data-name="维数（dimension）">

- 有限维向量空间的维度是这个向量空间中任意一个基的长度.
- 有限维向量空间 $V$ 的维数记为 $\operatorname{dim}V$.

</div>

<div class="math-env remark">

向量空间中任意一个基的长度实际上就是这个向量空间中能找到的线性无关的向量个数的最大值.

</div>

$\operatorname{dim}V$ 个线性无关的向量构成空间的一组基矢（basis vectors）.
  
- 任意空间中的向量可以唯一地表示为这组基矢的线性组合（反证法给出唯一性）.
- 线性组合的系数（coefficients）称为该矢量在这组基下的坐标（coordinates）.

### 图形学研究的维度

### 低维度向量和向量空间（2D~3D）

- 物理空间：Mesh、曲线、点云的坐标及导数.
  - 欧几里得空间（$x,y,z$）
  - 闵可夫斯基空间（$x,y,z,\mathrm{i}ct$）
  - 颜色空间：RGB, CMYK
- 高纬向量和向量空间
  - 灰度数字图像上所有像素值组成的向量.
    - $1920\times 1080$ 的灰度数字图像维度高达 $200$ 万.
  - 二维或三维图形的所有自由度组成的向量
    - 《原神》中纳西妲运动的自由度为 $45459$
    - SIGGRAPH 水体模拟求解的向量维度一般在 $10^6\sim 10^7$.

## 线性映射（Linear Mapping）

- $f:V\to W$
  - $V,W$均为向量空间
  - $f\left( \boldsymbol{u}+\boldsymbol{v} \right) =f\left( \boldsymbol{u} \right)+f\left( \boldsymbol{v} \right)$
  - $f\left( \alpha \boldsymbol{v} \right)=\alpha f\left( \boldsymbol{v} \right)$
- 推论
  - $f\left( \boldsymbol{0} \right)=\boldsymbol{0}$
  - $f\left( a \boldsymbol{u}+b \boldsymbol{v} \right)=af\left( \boldsymbol{u} \right)+bf\left( \boldsymbol{v} \right)$
- 低维空间的线性映射
  - 缩放、旋转是线性映射
  - 平移不是线性映射
  - 仿射变换（affine transformation）$=$ 缩放、旋转+平移

## 矩阵（Matrix）

- 什么是矩阵
  - 形式上：二维数组阵列（2D array）.
  - 意义上：线性映射的一种表示
- 矩阵运算的意义
  - 矩阵与向量的乘法：给出向量在新的空间（经过矩阵对应的线性变换后的空间）里的坐标
  - 矩阵的乘法：对空间的多次变换的复合
- 仿真
  - $n\times n$的矩阵，暗示变换前后空间的维度相同：
- 单位矩阵一般记为 $\mathbf{E}$ 或 $\mathbf{I}$

## 矩阵单目运算

- 转置（Transpose）$\mathbf{A}^{\mathrm{T}}$：$\mathbf{A}$ 的所有元素的下标的行、列互换.
  - 意义：矩阵对应的线性变换在对偶空间里的逆变换对应的矩阵.
  - 性质：$\left( \mathbf{A}\mathbf{B} \right)^{\mathrm{T}}=\mathbf{B}^{\mathrm{T}}\mathbf{A}^{\mathrm{T}}$
- 行列式（Determinant）：$\det \mathbf{A}=\left| \mathbf{A} \right|$
  - 意义：矩阵对应的线性变换对空间的拉伸程度的度量（物体经过变换前后的体积比）
  - 定义：在 $n$ 阶方阵中选 $n$ 个元素使得每行每列各有一个元素被选出，求其乘积，再将不同的选取方案乘以 $\pm 1$ （由选取翻案的奇偶性决定）加和
  - 计算方法
    - 低维矩阵：$n$ 条主对角线分别计算乘积的和，减去 $n$ 条次对角线分别计算乘积的和
    - 高维矩阵：高斯消元法后取对角线元素的积
  - 性质：转置不变，即 $\det \mathbf{A}^{\mathrm{T}}=\det \mathbf{A}$；交换行（列）取反
- 迹（Trace）$\operatorname{trace} \mathbf{A}$：矩阵的对角线元素之和
  - 意义：矩阵的特征值之和
  - 性质
    - $\operatorname{trace}\mathbf{A}=\operatorname{trace}\left( \mathbf{A}^{\mathrm{T}} \right)$
    - $\operatorname{trace} \mathbf{A}\mathbf{B}=\operatorname{trace} \mathbf{B}\mathbf{A}$
    - $\operatorname{trace}\left( \mathbf{A}+\mathbf{B} \right)=\operatorname{trace}\left( \mathbf{B}+\mathbf{A} \right)$
- 逆（INversed）$\mathbf{A}^{-1}$：满足 $\mathbf{A}\mathbf{A}^{-1}=\mathbf{A}^{-1}\mathbf{A}=1$ 的矩阵
  - 求解：伴随矩阵法；高斯消元法
  - 性质
    - $\left( \mathbf{A}\mathbf{B} \right)^{-1}=\mathbf{B}^{-1}\mathbf{A}^{-1}$
    - $\left| \mathbf{A} \right|^{-1}\left| \mathbf{A} \right|=\left| \mathbf{A} \right|\left| \mathbf{A} \right|^{-1}=\mathbf{E}$
- 伴随（Adjugated）$\mathbf{A}^{*}$：由 $\mathbf{A}$ 的每个元素的代数余子式 $A_{ij}$ 构成的矩阵
  - 代数余子式 $A_{ij}=\left( -1 \right)^{i+j}M_{ij}$
  - $M_{ij}$ 为余子式，即删除第 $i$ 行第 $j$ 列后的行列式的值
  - 性质：$\mathbf{A}\mathbf{A}^{*}=\mathbf{A}^{*}\mathbf{A}=\left| \mathbf{A} \right|\mathbf{E}$

## 特征值（Eigenvalues）

对于某些向量 $\boldsymbol{u}$ 满足 $\lambda \boldsymbol{u}=\mathbf{A}\boldsymbol{u}$ 的数 $\lambda$ 称为特征值，其中 $\mathbf{A}$ 为 $n$ 阶方阵

这些向量 $\boldsymbol{u}$ 称为特征向量，每个特征值对应的特征向量构成向量子空间（$\lambda \boldsymbol{u}=\mathbf{A}\boldsymbol{u},\lambda \boldsymbol{v}=\mathbf{A}\boldsymbol{v}\implies \lambda\left( \boldsymbol{u}+\boldsymbol{v} \right)=\mathbf{A}\left( \boldsymbol{u}+\boldsymbol{v} \right)$）

求解特征值：$\left( \lambda \mathbf{E}-\mathbf{A} \right)\boldsymbol{u}=0$

考虑关于 $\boldsymbol{u}$ 的非零解，则 $\left| \lambda \mathbf{E}-\mathbf{A} \right|=0$，该行列式对应于一个一元 $n$ 次方程

特征值的意义：对应某些向量，特定线性变换的作用效果与数乘等价（也可以说成对于一个线性变换，作用于特定向量的效果与数乘等价）

### 矩阵多项式的特征值

对于矩阵多项式：

$$
f\left( \mathbf{A} \right)=c_k\mathbf{A}^{k}+c_{k-1}\mathbf{A}^{k-1}+\cdots+c_1\mathbf{A}+\mathbf{c_0E}
$$

若 $\lambda$ 是 $\mathbf{A}$ 的特征值，则 $f\left( \lambda \right)$ 为 $f\left( \mathbf{A} \right)$ 的特征值

设 $\mathbf{A}$ 的特征值为：$\left\{ \lambda_1,\lambda_2,\cdots,\lambda_n\right\}$，则 $f\left( \mathbf{A} \right)$ 的全部特征值由 $\left\{ f\left(\lambda_1  \right),f\left(\lambda_2  \right),\cdots,f\left(\lambda_n  \right)\right\}$ 给出

重要应用：最大特征值成为谱半径（spectral radius），最大最小特征值之比称为条件数

## 赋范向量空间（Normaed Vector Space）

### 度量空间

向量空间中的元素不能比大小

对于集合 $V$，定义度量函数 $d: V\times V\to \mathbb{R}$，设 $x,y,z \in V$
- 非负性：$d\left( x,y \right)\geqslant 0$
- 定性（不可区分者的同一性）：$d\left( x,y \right)=0\Leftrightarrow x=y$
- 对称性：$d\left( x,y \right)=d\left( y,x \right)$
- 三角不等式：$d\left( x,z \right)\leqslant d\left( x,y \right)+d\left( y,z \right)$

定义了度量函数的集合 $V$ 成为度量空间（metric space），度量函数 $d$ 又称为「距离」

### 赋范向量空间

<div class="math-env definition" data-name="赋范向量空间">

如果一个空间既是向量空间，又是度量空间，则称为赋范向量空间

</div>

<div class="math-env remark">

$d\left( \boldsymbol{u},\boldsymbol{v} \right)=\left\| \boldsymbol{u}-\boldsymbol{v} \right\|$

</div>

<div class="math-env definition" data-name="范数">

$\left\| \cdot \right\|:V\to \mathbb{R}$，设 $\boldsymbol{u},\boldsymbol{v}\in V$
- 非负性：$\left\| \boldsymbol{u} \right\|\geqslant 0$
- 正定性：$\left\| \boldsymbol{u} \right\|=0\Leftrightarrow \boldsymbol{u}=\boldsymbol{0}$
- 正齐次性：$\left\| a \boldsymbol{u} \right\|=\left| a \right|\left\| \boldsymbol{u} \right\|(a\in \mathbb{R})$
- 次可加性、三角不等式：$\left\| \boldsymbol{u}+\boldsymbol{v} \right\|\leqslant \left\| \boldsymbol{u} \right\|+\left\| \boldsymbol{v} \right\|$

</div>

## 内积空间（Inner Product Space）

内积：$V\times V\to \mathbb{R}$

- $\left<\boldsymbol{u},\boldsymbol{v} \right> =\overline{\left<\boldsymbol{u},\boldsymbol{v} \right>}$
- $\left<\boldsymbol{u},\boldsymbol{v}+\boldsymbol{w} \right> =\left<\boldsymbol{u},\boldsymbol{v}\right>+\left<\boldsymbol{u},\boldsymbol{w} \right>$
- $\left<\boldsymbol{u},a \boldsymbol{v} \right> =\overline{a}\left<\boldsymbol{u},\boldsymbol{v} \right>$
- $\left<\boldsymbol{u},\boldsymbol{u} \right> \geqslant 0$
- 赋范向量空间 vs. 内积空间
  - $d\left( \boldsymbol{u},\boldsymbol{u} \right)=\left<\boldsymbol{u},\boldsymbol{u} \right>$
  - 范数只给出了向量的长度
  - 内积还给出了向量的夹角

<figure id="fig:vector_space">
    <img src="https://raw.githubusercontent.com/HikariOri/image/main/20250627164056788.png" alt="向量空间"/>
    <figcaption>线性空间、度量空间、赋范线性空间和内积空间的关系</figcaption>
</figure>

## 内积与正交

### 正交基底与单位正交基底

<div class="math-env definition" data-name="两向量夹角">

$$
\theta_{\boldsymbol{u}\boldsymbol{v}}=\arccos \frac{\left<\boldsymbol{u},\boldsymbol{v} \right>}{\sqrt{\left<\boldsymbol{u},\boldsymbol{u} \right>\left<\boldsymbol{v},\boldsymbol{v} \right>}}
$$

当 $\cos\theta_{\boldsymbol{u}\boldsymbol{v}}=0$ 时，称这两个向量正交.


</div>

## 幺正空间与幺正变换

## 低维变换矩阵

## 齐次坐标（Homogeneous Coordinates）

## 矩阵的变换

### 相似变换

### 合同变换

### 二次型（Quadra Form）：$n$ 个变量的二次多项式
 
## 正定矩阵与对称矩阵

### 正定矩阵（Positive-definite Matrix）

### 对称矩阵

## 矩阵分解（Decomposition）

### PLU 分解

### 乔里斯基（Cholesky）分解

### QR 分解

### 奇异值分解

## 向量与矩阵的范数

### 向量范数

### 矩阵范数

#### 诱导范数（Induced Norm）

#### 元素形式范数（Entrywise Norm）

#### 沙滕（Schatten）范数：一种不随幺正变换而改变的范数

## 矩阵求导

### 布局

### 向量变元的实值标量函数 $f\left( \boldsymbol{x} \right)$

### 矩阵变元的实值标量函数 $f\left( \boldsymbol{X} \right)$

### 矩阵函数的微分

### 利用矩阵微分求导

## 内积、外积与向量积

### 内积（标量积）

### 叉积（向量积）

### 外积（张量积）

### 克罗内克（Kronecker）积

## 内积空间
